{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. test the the complete data with all features on stacking model\n",
    "# 2. tune fcm with all features and imputed result of stacking model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hybrid_fcm_impute import HybridFCMImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# import csv\n",
    "\n",
    "X_train_complete = pd.read_csv('./Gas_Dataset/complete/X_train.csv')\n",
    "y_train_complete = pd.read_csv('./Gas_Dataset/complete/y_train.csv')\n",
    "X_test_complete = pd.read_csv('./Gas_Dataset/complete/X_test.csv')\n",
    "y_test_complete = pd.read_csv('./Gas_Dataset/complete/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_train_complete[:1000]\n",
    "X_te = X_test_complete[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Model: Stacking with complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_complete['Gas Class'] = y_train_complete['Gas Class'].apply(lambda x: x - 1)\n",
    "y_test_complete['Gas Class'] = y_test_complete['Gas Class'].apply(lambda x: x - 1)\n",
    "\n",
    "\n",
    "# check \n",
    "\n",
    "X_tr = X_train_complete[:1000]\n",
    "X_te = X_test_complete[:1000]\n",
    "y_tr = y_train_complete[:1000]\n",
    "y_te = y_test_complete[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stack_prediction(X_train, y_train, X_test, y_test):\n",
    "    catboost_model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='MultiClass', verbose=False, random_state=42)\n",
    "    xgboost_model = XGBClassifier(objective='multi:softmax', num_class=6, random_state=42)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    catboost_model.fit(X_train, y_train)\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # 生成預測機率\n",
    "    prob_catboost = catboost_model.predict_proba(X_test)\n",
    "    prob_xgboost = xgboost_model.predict_proba(X_test)\n",
    "    prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "    # Stacking model使用機率當feature\n",
    "    stacked_features = np.column_stack((prob_catboost, prob_xgboost, prob_rf))\n",
    "    stacking_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "    stacking_model.fit(stacked_features, y_test)\n",
    "\n",
    "    y_pred_stack = stacking_model.predict(stacked_features)\n",
    "    accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "    f1_stack = f1_score(y_test, y_pred_stack, average='macro')\n",
    "\n",
    "    print(\"Stacking Model Test Accuracy:\", accuracy_stack)\n",
    "    print(\"Stacking Model Test F1 Score:\", f1_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_stack_prediction(X_train_complete, y_train_complete, X_test_complete, y_test_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_stack_prediction(X_tr, y_tr, X_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCM with 0.25 missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([X_train_miss, X_test_miss])\n",
    "df = X_train_complete\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = pd.read_csv('./Gas_Dataset/X_train_top30.csv')\n",
    "tmp = X_tr.copy()\n",
    "tmp = tmp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def random_nan_half_rows(df, percentage):\n",
    "    num_entries = df.size\n",
    "    num_nans = int(num_entries * percentage / 100)\n",
    "    half_rows = df.sample(frac=0.5)\n",
    "    indices = np.random.choice(half_rows.size, num_nans, replace=False)\n",
    "    half_rows_flattened = half_rows.to_numpy().flatten()\n",
    "    half_rows_flattened[indices] = np.nan\n",
    "    half_rows_with_nans = pd.DataFrame(half_rows_flattened.reshape(half_rows.shape), columns=half_rows.columns)\n",
    "    df_with_nans = pd.concat([df.drop(half_rows.index), half_rows_with_nans])\n",
    "    return df_with_nans\n",
    "\n",
    "def count_complete_rows(df):\n",
    "    complete_rows = df.dropna()\n",
    "    num_complete_rows = len(complete_rows)\n",
    "    return num_complete_rows\n",
    "\n",
    "def missing_rate(df):\n",
    "    num_missing = df.isna().sum().sum()\n",
    "    total_entries = df.size\n",
    "    missing_rate = num_missing / total_entries\n",
    "    return missing_rate\n",
    "\n",
    "df_incomplete = random_nan_half_rows(tmp, 25)\n",
    "display(df_incomplete)\n",
    "\n",
    "print(count_complete_rows(df_incomplete))\n",
    "print(missing_rate(df_incomplete))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the dataframe using the scaler\n",
    "df_std = scaler.fit_transform(df_incomplete)\n",
    "\n",
    "# convert the standardized dataframe to a pandas dataframe\n",
    "df_std = pd.DataFrame(df_std, columns=df_incomplete.columns)\n",
    "\n",
    "# print the standardized dataframe\n",
    "print(df_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid_fcm_impute import HybridFCMImputer\n",
    "hfcmImputer = HybridFCMImputer(data = df_std, iter_num= 2)\n",
    "after = hfcmImputer.impute()\n",
    "display(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse transformation the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = scaler.inverse_transform(after)\n",
    "imputed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
